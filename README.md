naam: Daan Gielen
Studentnummer: 19072074


## Portfolio

## DataCamp course 
Within the data camp courses I completed 56%. Sometimes I found it hard to follow certain steps in the data camp courses. This made it  a bit  hard for me to finish up. 

[data camp courses completed](https://github.com/daantjuhg/Portfolio/blob/main/datacamp%20courses%20completed.JPG)
[data camp courses proof](https://github.com/daantjuhg/Portfolio/blob/main/datacamp%20courses%20proof.JPG)

## reflection on own contribution to the poroject
### situation
within the minor applied data science, over the last 17 weeks i worked on project wheels. We got the following assignment from the Dutch national wheelchair basketball team; how can we use IMU data to classify specific wheelchair basketball aspects of a game/match.  

### Tasks: 
Personally I always want to do good by the team, not lacking in working hours or ethic compared to other students. I also want to get the best result out of the project this means really pushing the boundaries of what we can learn and accomplish in 16/18 weeks of work. 

### Actions:
Personally, I think I had the least experience of coding in my project team. I tried completing the whole course but found this difficult in terms of overall work pressure. After learning quite a few new programming things I worked a lot with the data exanimating and explanation since, I my mind, this is my field of experience. I tried searching for the features that could support the explanation of movements.  After researching the features, I work on training and validating different models to learn how they work and how to apply them correctly. Personally, I like to do a few presentations, internal as well as external, because this gives me the opportunity to not only tell the class what we as a group are up to, but personally I use these presentations to learn what my peers have done so I can learn from their work in depth. Furthermore, I wrote parts in the research paper, the parts I wrote consists mostly of the models I worked on and the conclusion of the project. 

### Results
From all the Data camp assignments I completed 56% in total, but never missed any live colleges. Within the data I made several new features, 8 in total. I also gave every feature some sort of definition, so it is easy to sort them for the movements. I made sure that the decision tree an random forest models were working correctly by evaluating each feature input and tuned the models with grid search hyperparameter tuning. I gave a total of 2 internal and 2 external presentations in which I learned a lot about the work of my teammates. 

### Reflection:
In my opinion my contribution to the project was great. I was always there for our meetings. I tried to do as much coding as I could, sometimes my teammates could just do it faster, which was a great help for when I had questions. For the research paper I tried to keep an overview of the whole paper to help my team write correctly. As meeting leader, I also tried to keep the projects within boundaries which was sometimes hard and I needed think and discuss if some of our workways were leading to good results. In the end I am also quite pleased about my presentations, every time I got compliments for how my PowerPoints were setup and that I explained things in a nice way. Overall, I am quite happy with the way I took part in this project.  

## reflection on own learning objectives
### Situation
Within the minor applied data science, the past 17 weeks. I had lessons, assignments and a project in machine learning 

### Tasks 
Within the minor I wanted to learn how machine learning works, in my own study I have worked with data analysis through MATLAB.  I thought this minor would be a great next step in my data analysis knowledge. 

### Actions
The minor had 7 data/machine learning lectures and 3 to 4 neural network lectures; I can proudly say I missed none. The minor also gave access to Data camp course, I tried completing the whole course but found this difficult in terms of overall work pressure. the Data camp courses focus mainly on the machine learning part of the minor. The teachers also gave us some assignments within jupyter hub, these assignments helped students learn coding in pyhton with all of its possibility’s, well not all of them of course. Within the projects we had the possibility to apply everything we learned from the teachers directly to real world problems which was…. Challenging.  

### Results
As stated, before I missed none of the lectures within this minor. It gave me a good insight in the subjects, but I found it sometimes hard to follow because almost everything was new information for me. From all the Data camp assignments I completed 56% in total, in which I learned a lot about the different models and functions. Also, for this subject I sometimes found it hard to follow. As for the assignments in jupyter I did look into some of the subjects but never finished or submitted one. Within the project I wrote two models fully, RFC and decision tree. From the data camp courses I learned how to implement these models and how to tune their hyper parameters through gridsearch. 

### Reflection
I am happy with the things I have learned from this minor. Although at first it was sometimes hard to keep up. When I was learning for the test, I found that I understand everything from the presentations much better now, this was a ice revelation because before I started learning I thought I did not pick up this much information. Also, within Datacamp I had difficulties understanding the steps they take sometimes. It was frustrating and time consuming so maybe that is one of the reasons I did not finish it all the way. Within the project I found that it is hard to directly implement the things we are still learning. For me it was hard because at the start we did not know anything so how could we make an plan of approach to the whole problem. In the end I can look back on the whole experience and be happy with what I learned and what we as a group accomplished in the project. 

## evaluation on the group project as a whole
### Situation
In the last 18 weeks I worked with 4 other students on project wheels. The goal was to create a machine learning program that could analyze IMU data for wheelchair basketball specific actions. 

### Tasks 
Within this project we would need to stay in touch with our problem owner to succeed. We would work together to research and solve the problem. To enhance our chances of success the group needs to work with scrum. 

### Actions
At the start of the project, we needed to interview our real problem owner to get an idea for the scope of the project. From these interviews we created a plan of approach which we would send to the problem owner. Using scrum, the project group would meet every morning at 9.30 to update each other on our finished work a planning. We would also meet for retrospectives after every 2 sprint weeks. When we did enough research group members started working on writing machine learning codes. We would write a research paper from the findings we made within the project. 

### Results
the plan of approach helped us understand the scope, meaning and en result of our problem.  It gave everyone some guidelines through the whole project. The meetings every morning created a nice workspace and work timing. the daily standups also helped us to understand what every group member was doing. The retrospectives helped us expand our knowledge of scrum and we improved our scrum application with every sprint. Within the results we found some interesting findings we could bring to light within the research paper. Our non-defined dataset was indeed a pain in the ass but in the end, it was an interesting problem to solve. 

### Reflection
Within this group the project went pretty smooth in my opinion. The working environment we created was pretty sturdy but still flexible. We would meet 4 out of 5 school days at 9:30 in the morning. But if you had any questions throughout the day everyone was always helpful. We had one small incident involving a 5th member of the group. He unfortunately stopped with the minor. Throughout the rest of project, the collaboration only increased between the group members. In the end I am adequately happy to have been working with my team and the way we communicated and finished the project. 



## Domain knowledge 
### introduction to the subject field and literature research
Data is everywhere, from Netflix to google maps, we use and make data daily without noticing. This data is what this minor is all about. it can be used to predict/classify all sorts of different subjects, from predicting the cheapest day refilling your car to classifying which plant is which based on the color/length of the petals. Personally, I classified wheelchair movements with my project group. Below is an introduction into this subject with scientific proof researched by me. 
     
Phones track steps and different sport activities, able bodied people have their movement info at their fingertips. Research from [badar ud din Tahir,S., etall.(2020)](https://ieeexplore.ieee.org/document/9055944)shows that machine learning models are able to classify 12 different movements, walking forwards/walking left/ etc., correct with 73.33% accuracy. And a Study by [Zengtao Feng, etall.(2015)](https://ieeexplore.ieee.org/document/7319532) shows that people are still improving their training speed and test accuracy and stability for these movements through different predictive models.This second study also shows that random forest based models work better than more commonly used classifications and non-ensemble classifiers(KNN SVM BN J48). For wheelchair sports we see a slight research gap. Within wheelchair sports the research into classifying movements or sports in lacking. But in the paper from [R.M.Avan der Slikkeab, M.A.M.Berger, etall.,(2015)](https://www.sciencedirect.com/science/article/abs/pii/S0021929015003231?via%3Dihub) research we can conclude wheelchair sport analysis is on the rise. Wheelchair kinematic analysis may be the first and crucial push this field needed to expand the knowledge of wheelchair movements. 
Further research into the project will be explained later in the portfolio.

## Research project
### Task definition 
Like I said before, abled persons have the ability to easily track and monitor their activities throughout the day. With only a phone you can already see your steps, activity time and calorie count. Most phones even have an app with which you can track your performance in trainings like running, swimming or cycling. We see a pattern here; all commonly available sports trackers are focused on steps. But wheelchairs roll you might say, yes, they do. But just like walking has a rhythm, so does riding. This would mean that wheelchair riding could also be monitored.

This is where our project comes into play, IMU’s are used to track wheelchair movements in basketball games.  Our goal is to apply this data in machine learning models and extract selected wheelchair movements like sprints.  to reach this goal, the project group set up the following research question with some sub questions, to reach the end goal.

- How can IMU data be used to identify wheelchair basketball-specific movements?
  -	Which form of data processing will be used?
  -	Which specific movements can be detected?
  -	Which sensor data is used for each movement?
  -	Can movements be used to predict fatigue?
  -	Can movements be used to detect overload? These sub question will help us to get an answer to the main research question.

further research and supporting reasons for these questions can be found in the [Plan of Approach](https://github.com/daantjuhg/Portfolio/blob/main/Planofapproach.pdf).

### planning
To reach the end goal of this project in a orderly way the team set up a azure devops, https://dev.azure.com/Wheeeeeeeeeeeeeeels/wheels/_boards/board/t/wheels%20Team/Stories_m_. it was a bit getting used to in the beginning and because of time issues it was also hard to finish it up, but this website helped us a lot keeping track of tasks. Our daily standup would start at 9:30 to discuss/evaluate everyone’s assignments from the day before and explain the planning for today. This would keep the team up to date on the process so we could help each other easily if necessary. Sprints within this project are 2 weeks short, we would evaluate the sprints through a retrospective. In this meeting we would take the time to talk about the group’s strengths and weaknesses. This list would be summed up into three categories, keep/remove/improve. We would also take these times to settle debates between group members and made sure everyone was okay. After the retrospective we would also discuss the new sprint planning. In which we would come up with user stories to complete over the next couple of weeks. Finally, we would determine which user story was most important and how much time it would take to complete. Time for completion gave the group possibility to divide the workload equally. 

In the [Plan of Approach](https://github.com/daantjuhg/Portfolio/blob/main/Planofapproach.pdf) Is also an attachment, called ‘planning’, I made for the group. Looking at this planning from time to time gave us an overall overview of how many weeks we still had and helped set up for the next step in the project. Looking back on it the planning was quite short and hefty at the start. Personally, I should have planned more time for research and setup of the project. Personally, I did a few other things and was not so committed to the research part. It should have been my job to communicate better about the planning of the research and discuss this with the group.

### conclusions
From my research, [stated above Zengtao Feng, etall.(2015)](https://ieeexplore.ieee.org/document/7319532),  we found that an RFC model outperforms other models. Martijn found a few papers that would use neural networks for the classification of IMU data. One even stated [Muralidharan, K., Anirudh, R., (2021)](https://www.sciencedirect.com/science/article/pii/S2666307421000140) that when using smartphone sensor data to classify different movements RNN would severely outperform RFC wich stands in contradictio to my papers. Therefore, later in the project we focust on these two models. 

In this project we developed a method to classify wheelchair movements through IMU data. In our case this was done by expanding our dataset which only had 2.3% defined for movements, in our case the movement is sprinting.  The group used the RFC and RNN models to collect/compare and analyze false positive data predictions to define the dataset. We improved the dataset to 17.1% tagged sprints. we found that the RFC model was more accurate on the training ad validation set by 4%, we decided to proceed to testing with this model. The test set consist of unknown data from another unanalyzed player. The RFC classified sprints with a precision of 91.67% recall and accuracy are unfortunately unknown because of the unidentified dataset. Anyhow, these results show that (even) partially defined IMU data can be used to classify sprints through RFC and RNN model. 


### evaluation
Within this project the main goal shifted a bit because of time problems. Instead of trying to classify movements in wheelchair basketball matches, we started focusing on solely sprints. the main question would stay the same as one movement would still show the possibilities of the IMU recordings. 

This question was answered indeed by showing the precision in which the sprints are classified. But this is only the beginning, from here on out the method could be used to classify other movements. The most important part for these new classifications is that movements need to be further researched. Right now, the movements do not have definition or meaning. So further research should be done for patterns in different wheelchair movements.

This project group focused the study on players within the same paralysis level. Within wheelchair basketball paralysis levels are used to classify players. During matches the teams can create a lineup with a maximum number of points. Athletes with higher paralysis levels have a lower score. With this first step to classifying movements. We believe it may be possible to classify the same pattern movements between players with different paralysis levels. Personally, I think this research should focus on the feature engineering most because there is a lot to gain. 

Besides using this technique for athletes only, we hope it is possible to convert this classification study for daily use. Research should look into the characteristics of normal wheelchair push offs using phone or smartwatch accelerometers instead of IMU’s. this way wheelchair users can track their activities just like we can every day. 

## Predictive analytics
  ### selecting a model
The first models: 

At the start of the project, I wanted to jump into coding with machine learning models. Since I had no previous experience with coding except for MATLAB. I wanted to try things within jupyter and help the group.  I stared training models like KNN, decision tree and SVC, because these models are explained quite quickly in the data camp course. With no clear goal in mind than just learning how to use jupyter and prepare models. 

A little time later decision tree was found to be useful. More on that in the training subject. 

RFC:

The following papers used RFCs to classify human movement analysis with IMU data. these papers i found [badar ud din Tahir,S., etall.(2020)](https://ieeexplore.ieee.org/document/9055944) [Zengtao Feng, etall.(2015)](https://ieeexplore.ieee.org/document/7319532) are comparing RF classifier to other machine learning algorithms. They compare accuracy, stability and training time, in which RFC comes on top. Both of these papers use sensor data, one of which uses similar to IMU sensors; 3-axis gyroscope and 3 axis accelerometers, to investigate and classify movements or sports. 

  ### Training and configuring a model
After I setup the two models I trained them using the dataset we explored from player A.

The first time running the decision tree model I split the chunk data, created by martijn, in 80% training 20% validation. the whole dataset contained +- 6000 datapoints from which 100 were tagged sprints. this means the validation set had +- 25 tagged sprint points in +- 1500 datapoints. I tuned this decision tree to 100% recall. In the document [Decision tree](https://github.com/daantjuhg/Portfolio/blob/main/decision%20tree%20sprints.ipynb) you can see that I got a lot of false positive results, these results were stored in a csv file for evaluation later. In the evaluation I will elaborate more on the evaluation of this method. 

For the [RFC model](https://github.com/daantjuhg/Portfolio/blob/main/RandomForrestCLassifier%20sprints.ipynb) we used later in the project i split the data in two parts a training part and validation part, 75% to 25%. First time selecting two features the RFC underfitted this was visualized by plotting a confusion matrix, precision: 86.25% and recall: 69.9%. which is not too bad for a first try, how this is possible will be explained in the chapter data preparation/visualization. After this first try, I made a gridsearch to find better hyperparameters. I made sure to run the model every time with random_state = 42, this way my findings would be comparable. The hyperparameters I tuned were: n_estimators, min_samples_leaf, criterion and max depth. 

From gridsearch and the graphs we can see that gridsearch gives us: 80, 2, gini, 14 as best numbers from the test. But in the RFC below we can see that I eventually went with the numbers: 100, 3, gini, 14. I did this because the numbers I chose had a better recall score by 3% by losing precision of less then 1%. This is important for our project because missing sprints in your match analysis is bad. (plus, we don’t know for certain if the dataset is fully tagged so false positives could be correct sprints. 

  ### evaluating & visualizing a model
  
Evaluating models was not as easy as it seemed. The dataset provided by our problem owner was not complete. After I first made the [Decision tree](https://github.com/daantjuhg/Portfolio/blob/main/decision%20tree%20sprints.ipynb) model, martijn created a [false positive visualization](https://github.com/MartijnKok/Portfolio/blob/main/Data_Visualization/Check_False_Positives.ipynb)(links you to martijn his github). This code helped martijn and I to check the first false positives of the code. We found that +-50% of the data was positive sprints, we used this to further complete the dataset and let Collin rerun this process one or two more times. After this method we spoke with Jeroen and found another way to find and correct the false positives, this is explained within [the research paper](https://github.com/daantjuhg/Portfolio/blob/main/Research_Paper_Project_Wheels.pdf) page 3 Alinea 3 After this method we are positive that the data is complete enough to run valid, training validation ad testing. 

For my [RFC model](https://github.com/daantjuhg/Portfolio/blob/main/RandomForrestCLassifier%20sprints.ipynb) (that used the final dataset stated above) I used a confusion matrix to evaluate and visualize the outcome. From this plot I could calculate the recall score, precision score and accuracy of the model. Below I will show the scores over the training & validation set since this was what I did. 
  
## Data preprocesing
  ### Data exploration 
At the start of the project martijn and I looked at a lot of data. We made graphs of basketball fast offences and fast defenses. In these graphs we tried looking for movements, Rienk his intern tagged video data we could use to find these. The specific movements we looked for was a 180-degree rotation followed by a sprint. Martijn plotted two features, wheelrotationalspeedX and framrotationalspeedZ, which are indeed the two most important features for these movements. Sometime later in the project I found myself tinkering with these features to find other patterns for these movements. In [visualization function fast offence](https://github.com/daantjuhg/Portfolio/blob/main/Visualisation%20function%20Fast%20offense.ipynb), you can see that I tinkered with the variables and plotted them to see which feature would be useful in different situations. Behind the features/variables I have written down what movements influences it. In my [RFC model](https://github.com/daantjuhg/Portfolio/blob/main/RandomForrestCLassifier%20sprints.ipynb) i made some plots to visualize features to try and find correlations. wich could be used in feature selection.
  
  ### Data preperation 
 Balancing the data, our data was very unbalanced at first. Were martijn wrote a script for balancing the data for sprints I have written one for rotations, [balancing dataset rotations](https://github.com/daantjuhg/Portfolio/blob/main/balancing%20dataset.ipynb). In my program I copied and pasted the data a few times to get a total set of +- 530000 datapoints with +- 80000 tagged rotations, around 15%. My plan was to use this data to train the models and find more accurately the false positive rotations. Sadly, I could not check my theory because of time issues. 
  
  ### Data explanation 
Our dataset consisted of multiple measurements. The first being the IMU data. The wheelchair basketball players had 2 imu’s on their wheelchair, one on the frame and one on the wheel. Both IMU’s have 3 accelerometers and 3 gyroscopes. Rienk pre calculated the imu data to workable features, we ended up with 3 axis features for each of the IMU(XYZ) and we ended up with an additional 7 features for the movements of the entire wheelchair, the rotational: speed/acceleration/angle and the forward: speed/acceleration/displacement. 
Actions that athletes make during matches were tagged by rienk his intern, he would watch the video and write down what movement was made at wich time in the game. These movements, our ground truth, needed to be implemented into the dataset and synchronized to the timeline. 

  ### Data visualization 
i refer to my previous statements about visualization in the following documents:
 [visualization function fast offence](https://github.com/daantjuhg/Portfolio/blob/main/Visualisation%20function%20Fast%20offense.ipynb)
 [RFC model](https://github.com/daantjuhg/Portfolio/blob/main/RandomForrestCLassifier%20sprints.ipynb)
 
## communication 
 Whitin the project I got the task to lead meetings, especially in the first few weeks of the project. In these weeks it is important to know what the group wants to talk about because the group needs to have a clear grasp of the project. My job was to make meeting agenda’s, watch the meeting times, lead the conversation, make everyone speak, and touch upon all the subjects. 
 
Also, I have lead 3 presentations during the project 1 internal meetings and 2 external meetings [presentation 1](https://www.canva.com/design/DAEsOMon0GU/xlIWuiH1R03dwnfPvZCykA/view?utm_content=DAEsOMon0GU&utm_campaign=designshare&utm_medium=link&utm_source=publishsharelink#1) [presentation 2 with collin](...). I not only tried to just do the presentations I also used these times to catch upon work within the group. We are working with a lot of IT specialists which means sometimes not every piece of work is explained to the fullest. In the presentations I tried to get a clear view of everyone’s work so the presentations can be explained more in depth. 

Further in the paper I have written a few parts myself. Someone within the group made a setup for the paper wich needed to be tinkered a lot. With the whole group we made work of it. We made several meetings to write the paper. In these meetings martijn and I generally lead the meetings. We walk through the paper and the comments written. From these comments we made tasklists to divide between the group.

